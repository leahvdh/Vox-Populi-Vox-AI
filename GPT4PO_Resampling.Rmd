---
title: "GPT for Public Opinion: Resampling"
author: "Leah von der Heyde"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
library(checkmate)
library(rgpt3)
```


```{r}
# Import data
resample <- read.csv("GPT4PO_manual_resample.csv") # read in data for resampling
resample <- resample %>% mutate(id_sampleno = paste(id, sample_no, sep = "_")) # should have been used as ID-variable in API, but will be used ot match later
```

Get API access

```{r}
gpt3_authenticate("access_key.txt") # Key in das txt (ohne Anführungszeichen, Name, etc. NUR der key, mit new line dahinter!) 
# gpt3_test_completion() # Test key
```

Feed prompts and store completions

```{r}
output_resample <- gpt3_completions(
                    prompt_var = resample$prompt
                  , id_var = resample$id
                  , param_model = 'text-davinci-003'
                  , param_output_type = "complete" # save both completion and metadata
                  , param_logprobs = 5 # numeric. deprecated :(
                  , param_suffix = NULL #character. The suffix that comes after a completion of inserted text
                  , param_max_tokens = 30 # 1 token is about 4 characters in English text. Test used between 10 and 50
                  , param_n = 1 # number of completions. Prompt tokens are only charged once.
                  , param_temperature = 0.9 # specifying the sampling strategy of the possible completions. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer. We generally recommend altering this or top_p but not both.
                  , param_top_p = 1 # specifying sampling strategy as an alternative to the temperature sampling where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.
                  , param_presence_penalty = 0 # numeric (default: 0) between -2.00 and +2.00 to determine the penalisation of repetitiveness if a token already exists. Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
                  , param_frequency_penalty = 0 # see presence_penalty
                  , param_best_of = 1 # numeric (default: 1) that determines the space of possibilities from which to select the completion with the highest probability. Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token.
                  )

completions_resample_df <- output_resample[[1]] # extract completions

metadata_resample_df<- output_resample[[2]] # extract metadata

save(resample, completions_resample_df, metadata_resample_df, file = "GPT_prompt_resample.Rdata") # save input and output
```

# Match 1: Completions - Party Keywords

```{r}
get_matches_vector(keywords = sequences, column = completions_resample_df$gpt3)

get_check_values(c("Erststimme", "ungültig", "nicht"), get_matches_vector(keywords = sequences, column = completions_resample_df$gpt3))

match_completions_resample <-  create_match_completions_df(completions_resample_df, keywords = sequences, check_keywords = c("Erststimme", "ungültig", "nicht"))
```

!!! MANUAL CHECKS NEED TO HAPPEN AT THIS STEP !!!

```{r}
# Export for manual checks
write.csv(match_completions_resample, file = "GPT4PO_manualchecks_resample.csv")
```

## Import checked data and build new identifier for merging

```{r}
match_completions_resample <- read.csv("GPT4PO_manual_resample_checked.csv") # read in checked data

resample <- resample %>% arrange(id) # sort

match_completions_resample <- match_completions_resample %>%
  arrange(id) %>% # sort 
  mutate(id_sampleno = paste(id, resample$sample_no, sep = "_")) # add new identifier
```

```{r}
is_identifier <- function(column) {length(unique(column)) == length(column)}

is_key_unique <- is_identifier(resample$id_sampleno) # check for resample
if (is_key_unique) {
  print("Key column is unique.")
} else {
  warning("Key column is not unique.")
}
```

```{r}
is_key_unique <- is_identifier(match_completions_resample$id_sampleno) # check for matching data
if (is_key_unique) {
  print("Key column is unique.")
} else {
  warning("Key column is not unique.")
}
```

## Create mc_resample
```{r}
# Joins matching and GLES datasets by ID to compare match with vote
mc_resample <- left_join(match_completions_resample, resample, by = c("id_sampleno" = "id_sampleno"))

all(mc_resample$id.x == mc_resample$id.y) # Check if ID columns are the same: yes

mc_resample <- mc_resample %>%
               select(-id.y) %>%
               rename(id = id.x)

save(mc_resample, file = "mc_resample.Rdata") # save as backup
```
