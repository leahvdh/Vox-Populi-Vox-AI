---
title: "GPT Public Opinion"
author: "Leah von der Heyde, Alex Wenz, Caro Haensch"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Set WD & get data
```{r}
#setwd("/Users/leah/Documents/GitHub/GPT-for-Public-Opinion")
# if not in environment from re-creating from scratch:
#load("GLES2017.Rdata")
```


Get API access

```{r}
# devtools::install_github("ben-aaron188/rgpt3") # Installieren
library(rgpt3) # Laden
gpt3_authenticate("access_key.txt") # Key in das txt (ohne Anführungszeichen, Name, etc. NUR der key, mit new line dahinter!) 
# gpt3_test_completion() # Test key
```

## To Dos:
- Find out how to store logprobs! --> Cannot be pulled :(

- Confirm which language model Argyle et al. used --> Davinci
- Confirm which temperature / top_p Argyle et al. used --> temperature = 0.7, top_p = 1
- Check if Argyle et al. used penalties for party ID / ideology --> No, but tested without
- Check if Argyle et. al used best of --> No mention

## Pilot:
- Try out different max_tokens. 20 allows for space for the entire completion sequence in theory, but sometimes doesn't get to the point fast enough and isn't always on point with temperature = 1
- Try [MASK] vs. [INSERT] --> choose one that's most stable
- Try out different temperatures (1 = probabilistic, 0 = deterministic) and top_ps.
- Try best_of

## Decisions to make:
- What's our final max_tokens?
- Do we use [MASK] or [INSERT]?
- Which size temperature? --> Stay with defaults, but which? Function: 0.9, Playground: 1? Argyle: 0.7
- How many completions per persona do we want? We can't record the probabilities, so we should create a sampling distribution!
- Alternatively: Should we use best_of and have GPT record the best of x completions based on logprobs (more obscure)?
Anticipated cost per run: 12 USD (ca 2000 personas, 250+50 300 tokens per persona)

# IMPLEMENTATION

Create prompt dataset from GLES data

```{r}
prompts_df <- data.frame(
              prompt_id = GLES2017$lfdn,
              prompt = GLES2017$prompt)

prompts_df <- prompts_df %>% head(3) # for testing; remove for running on full dataset
```

Feed prompts and store completions

```{r}
output <- gpt3_completions(
                    prompt_var = prompts_df$prompt
                  , id_var = prompts_df$prompt_id
                  , param_model = 'text-davinci-003'
                  , param_output_type = "complete" # save both completion and metadata
                  , param_logprobs = 5 # numeric. deprecated :(
                  , param_suffix = NULL #character. The suffix that comes after a completion of inserted text. Maybe use "gewählt"? So we can have "Ich habe [INSERT] gewählt" which supports "nicht" and "ungültig" as well as any party insert. Would ensure more on-point responses but might reduce likelihood of "nicht"?
                  , param_max_tokens = 30 # 1 token is about 4 characters in English text. Test used between 10 and 50
                  , param_n = 1 # number of completions. Expensive! Increase since we can't record probabilities?
                  , param_temperature = 0.9 # specifying the sampling strategy of the possible completions. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer. We generally recommend altering this or top_p but not both.
                  , param_top_p = 1 # specifying sampling strategy as an alternative to the temperature sampling where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.
                  , param_presence_penalty = 0 # numeric (default: 0) between -2.00 and +2.00 to determine the penalisation of repetitiveness if a token already exists. Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
                  , param_frequency_penalty = 0 # see presence_penalty
                  , param_best_of = 1 # numeric (default: 1) that determines the space of possibilities from which to select the completion with the highest probability. Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token. Eats money! Should we use this in place of n?
                  )

completions_df <- output[[1]] # save completions

metadata_df <- output[[2]] # save metadata
```

Create data frame for checking vote match.
Check what parties the completions include. If the completion includes keywords for multiple parties, "Erststimme", not having voted or having voted irregularly, mark these cases so we can check manually.

Open questions:
- Should the keywords also include "andere" and "linke"? What about "konservativ", "liberal", "kommunistisch"?
- When & how to check & manipulate manual checks: before joining or before checking match? Do we manipulate the data (new column) according to what we read?

```{r}
# insert Max' final code

```


Next step: match completion and GLES2017$vote, record as 1 if matching, 0 otherwise.

Matches (GLES | gpt3):

CDU/CSU | CDU, CSU, CDU/CSU, Union
SPD | SPD, sozialdemokrat
Bündnis 90/Die Grünen | Grüne (besser *grün* ? ), B90, Bündnis
FDP | FDP, freie, liberal
Die Linke | Linke, links (besser *link* ?)
AfD | AfD, Alternative
andere Partei, ungültig gewählt, nicht gewählt: need to double-check and determine accordingly

```{r}

# insert Max' final code

```

