---
title: "GPT Public Opinion"
author: "Leah von der Heyde, Alex Wenz, Caro Haensch"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Set WD & get data
```{r}
#setwd("/Users/leah/Documents/GitHub/GPT-for-Public-Opinion")
# if not in environment from re-creating:
#load("GLES2017.Rdata")
```


Get API access

```{r}
# devtools::install_github("ben-aaron188/rgpt3") # Installieren
library(rgpt3) # Laden
gpt3_authenticate("access_key.txt") # Key in das txt (ohne Anführungszeichen, Name, etc. NUR der key, mit new line dahinter!) 
gpt3_test_completion() # Test key
```

# TEST

Using R instead of playground:

```{r}
gpt3_single_completion(output_type = "text",  # makes output easier
                       max_tokens = 7,        # increases likelihood of usable content
                       model = "text-davinci-003",
prompt_input = "I am 30 years old and female. I have a university degree,
a middle-class income, and I am employed. I am not religious.
Ideologically, I am moderately left-leaning. I live in western Germany.
In the 2017 parliamentary election, I voted for [insert]") # (edited) 
```

Prompt to say whether person voted and if so, whom

```{r}
gpt3_single_completion(output_type = "text",  # makes output easier
                       max_tokens = 30,        # increases likelihood of usable content
                       model = "text-davinci-003",
prompt_input = "I am 30 years old and male. I have no degree,
no income, and I am unemployed. I am not religious.
Ideologically, I am left-leaning. I live in eastern Germany.
In the 2017 parliamentary election, did I vote and if so which party did I vote for?
Start with In the 2017 election, I [insert] ")
```


## To Dos:
- Find out how to store logprobs!

- Confirm which language model Argyle et al. used

- Confirm that this package really uses GPT-3 (and check whether there are options for using GPT-3.5/4)
Not clear from OpenAI documentation what model text-davinci-003 currently runs on? And whether rgpt3 overwrites this with GPT-3? Seems to be GPT-3 in any case. Can sign up for 3.5/4-API but would have to build our own API wrapper/access. Might revert to Argyle Python code for this.

- Check the set of tokens for which Argyle et al. recorded and cumulated the probabilities
- Confirm which temperature / top_p Argyle et al. used
- Check if Argyle et al. used penalties for party ID / ideology
- Check if Argyle et. al used best of

## Pilot:
- Try out different max_tokens. 20 allows for space for the entire completion sequence, but it isn't always on point with temperature = 1
- Try [MASK] vs. [INSERT]
- Try with/without suffix "gewählt"
- Try out different temperatures (1 = probabilistic, 0 = deterministic) and top_ps.
- Try out penalties and prompt with/without party ID / ideology
- Try best_of

## Decisions to make:
- What's our final max_tokens?
- Do we use [MASK] or [INSERT]?
- Do we use the suffix "gewählt" (Ich habe [INSERT] gewählt") or not ("Ich habe [INSERT]")?
- Do we choose temperature or top_p? Which size?
- Do we penalize for party ID / ideology (cannot specify) or leave it out completely or leave it in?
- Do we only want best_of?
- How many completions per persona do we want? If we can record the probabilities, 1 is enough, otherwise, we should create a sampling distribution

# IMPLEMENTATION

Create prompt dataset from GLES data

```{r}
prompts_df <- data.frame(
              prompt_id = GLES2017$lfdn,
              prompt = GLES2017$prompt)

prompts_df <- prompts_df %>% head(3) # for testing
```

Feed prompts and store completions

```{r}
output <- gpt3_completions(
                    prompt_var = prompts_df$prompt
                  , id_var = prompts_df$prompt_id
                  , param_model = 'text-davinci-003'
                  , param_output_type = "complete" # also save metadata just to be safe
                  , param_logprobs = 5 # numeric. Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response. The maximum value for logprobs is 5. THIS IS WHAT WE NEED! Where is it being stored? Did Argyle create a set of "accepted" tokens and added those probabilities?
                  , param_suffix = NULL #character. The suffix that comes after a completion of inserted text. Maybe use "gewählt"? So we can have "Ich habe [INSERT] gewählt" which supports "nicht" and "ungültig" as well as any party insert. Would ensure more on-point responses but might reduce likelihood of "nicht"?
                  , param_max_tokens = 50 # 1 token is about 4 characters in English text. Test used between 10 and 50
                  , param_n = 1 # number of completions. Expensive! Increase if we can't record probabilities?
                  , param_temperature = 1 # specifying the sampling strategy of the possible completions. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 for ones with a well-defined answer. We generally recommend altering this or top_p but not both.
                  , param_top_p = 1 # specifying sampling strategy as an alternative to the temperature sampling where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.)
                  , param_presence_penalty = 0 # numeric (default: 0) between -2.00 and +2.00 to determine the penalisation of repetitiveness if a token already exists (from the official API documentation: Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.) Should we use this for ideology / party ID?
                  , param_frequency_penalty = 0
                  , param_best_of = 1 # numeric (default: 1) that determines the space of possibilities from which to select the completion with the highest probability (from the official API documentation: Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token). Eats money! Should we use this?
                  )

completions_df <- output[[1]] # save completions

metadata_df <- output[[2]] # save metadata
```

Create data frame for checking vote match.
Check what parties the completions include. If the completion include hints for "Erststimme", not having voted or having voted irregularly, mark these cases so we can check manually. (Needs to be fixed to include "nicht" and "ungültig"!) Should also include "andere" and "linke"? What about "konservativ", "liberal", "kommunistisch"?

```{r}
# Specify the character sequences to search for
sequences <- c("SPD", "CDU", "CSU", "Union", "CDU/CSU", "FDP", "AfD", "Linke", "Grüne", "Bündnis", "B90", "sozialdemokrat", "christlich", "frei", "Alternative", "nicht", "ungültig", "Erststimme")

# Create an empty data frame to store the extracted data
pre_match_df <- data.frame(
  source_column = character(),
  extracted_characters = character(),
  check_manually = integer()
)

# Iterate over rows in the completions_df$gpt3 column
for (row in completions_df$gpt3) {
  # Initialize an empty vector to store the matched sequences
  matched_sequences <- character()

  # Iterate over the specified character sequences
  for (sequence in sequences) {
    # Check if the row contains the current sequence
    if (grepl(sequence, row, ignore.case = TRUE, fixed = TRUE)) {
      # Append the matched sequence to the vector
      matched_sequences <- c(matched_sequences, sequence)
    }
  }

  # Check if any matches were found
  if (length(matched_sequences) > 0) {
    # Check if the row contains "Erststimme", "nicht", or "ungültig" - doesn't work for "nicht" / "ungültig"
    check_manually <- ifelse(grepl("Erststimme", row, ignore.case = TRUE, fixed = TRUE) | grepl("nicht", row, ignore.case = TRUE, fixed = TRUE) | grepl("ungültig", row, ignore.case = TRUE, fixed = TRUE), 1, 0)

    # Append the extracted data to the pre_match_df
    pre_match_df <- rbind(pre_match_df, data.frame(source_column = row, extracted_characters = paste(matched_sequences, collapse = ", "), check_manually = check_manually))
  }
}

# Remove the empty first row from the pre_match_df
pre_match_df <- pre_match_df[-1, ]

```

Save created datasets
```{r}
# Specify the objects to exclude from saving
objects_to_exclude <- c("GLES2017", "GLES2017_original", "output", "sequence", "sequences", "row", "matched_sequences", "check_manually", "api_key")

# Get a list of all objects in the global environment
all_objects <- ls()

# Determine the objects to save by excluding the specified objects
objects_to_save <- setdiff(all_objects, objects_to_exclude)

# Remove excluded objects list
rm(objects_to_exclude)
rm(all_objects)
rm(objects_to_save)

# Save the selected objects into an .RData file
save(list = objects_to_save, file = "GPT_prompt_completion.RData")

```


Next step: match completion and GLES2017$vote, record as 1 if matching, 0 otherwise.

Matches (GLES | gpt3):

CDU/CSU | CDU, CSU, CDU/CSU, Union
SPD | SPD, Sozialdemokrat
Bündnis 90/Die Grünen | Grüne, B90, Bündnis
FDP | FDP, freie
Die Linke | Linke
AfD | Afd, Alternative
andere Partei, ungültig gewählt, nicht gewählt: need to double-check and determine accordingly

```{r}

```

